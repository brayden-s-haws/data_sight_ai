{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"9f3e2ca6-e2d9-4be5-b2b1-d761a410618b\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_name = _hex_json.loads(\"\\\"DataSight AI\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_status = _hex_json.loads(\"\\\"In Progress\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_categories = _hex_json.loads(\"[\\\"External\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"This app allows users to quickly onboard themselves to the contents of a database. ¬†It uses standard data tools and Generative AI agents to surface information about the data. Currently it offers: \n* AI generated descriptions for each table\n* Data preview and column stats \n* AI generated table relationship details \n* Natural language querying via an LLM-based agent \n\n(This is meant to be a proof of concept for how AI tools can help users better understand and work with their data.)\n\nComing Soon üó∫Ô∏è:\n* AI generated ERDs\n* Advanced query agent with Error handling and recovery\n* AI recommended visualizations\n\nYou can get technical details and access to the code on [GitHub](https://github.com/brayden-s-haws/data_sight_ai/tree/main).","metadata":{}},{"cell_type":"code","source":"\"\"\"\nImport non-standard packages\n\"\"\"\n\n!pip install langchain langchain-experimental\n!pip install sqlalchemy-bigquery","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Requirement already satisfied: langchain in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (0.0.347)\nCollecting langchain-experimental\n  Downloading langchain_experimental-0.0.47-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (1.4.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: anyio<4.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (3.6.2)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (0.5.9)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-core<0.1,>=0.0.11 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (0.0.11)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (0.0.69)\nRequirement already satisfied: numpy<2,>=1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (1.23.4)\nRequirement already satisfied: pydantic<3,>=1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (1.10.12)\nRequirement already satisfied: requests<3,>=2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (2.28.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from langchain) (8.2.2)\nCollecting langchain\n  Downloading langchain-0.0.353-py3-none-any.whl.metadata (13 kB)\nINFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-experimental\n  Downloading langchain_experimental-0.0.46-py3-none-any.whl.metadata (1.9 kB)\nCollecting langchain-core<0.1,>=0.0.11 (from langchain)\n  Downloading langchain_core-0.0.13-py3-none-any.whl.metadata (978 bytes)\nCollecting langchain-community<0.1,>=0.0.2 (from langchain)\n  Downloading langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\nINFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain\n  Downloading langchain-0.0.352-py3-none-any.whl.metadata (13 kB)\n  Downloading langchain-0.0.351-py3-none-any.whl.metadata (13 kB)\n  Downloading langchain-0.0.350-py3-none-any.whl.metadata (13 kB)\n  Downloading langchain-0.0.349-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: attrs>=17.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.6)\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.17.0)\nRequirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (1.5.1)\nRequirement already satisfied: typing-inspect>=0.4.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n  Downloading langchain_community-0.0.5-py3-none-any.whl.metadata (7.1 kB)\n  Downloading langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_community-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_community-0.0.2-py3-none-any.whl.metadata (5.8 kB)\n  Downloading langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.1,>=0.0.11->langchain)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2021.10.8)\nRequirement already satisfied: greenlet!=0.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\nRequirement already satisfied: sniffio>=1.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nDownloading langchain_experimental-0.0.46-py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.349-py3-none-any.whl (808 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m808.6/808.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.0.13-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, langchain-core, langchain-community, langchain, langchain-experimental\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.0.11\n    Uninstalling langchain-core-0.0.11:\n      Successfully uninstalled langchain-core-0.0.11\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.0.347\n    Uninstalling langchain-0.0.347:\n      Successfully uninstalled langchain-0.0.347\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nhex-packages 0.1.0 requires pyspark<4.0.0,>=3.4.1, which is not installed.\nhex-packages 0.1.0 requires grpcio<2.0.0,>=1.56.0, but you have grpcio 1.50.0 which is incompatible.\nhex-packages 0.1.0 requires grpcio-status<2.0.0,>=1.48.0, but you have grpcio-status 1.41.0 which is incompatible.\nhex-packages 0.1.0 requires packaging==21.3, but you have packaging 23.2 which is incompatible.\nhex-packages 0.1.0 requires snowflake-snowpark-python[pandas]==1.6.1, but you have snowflake-snowpark-python 1.11.1 which is incompatible.\nhex-packages 0.1.0 requires vegafusion-python-embed==1.4.2, but you have vegafusion-python-embed 1.5.0 which is incompatible.\npython-kernel-startup 0.1.0 requires snowflake-connector-python==3.1.0, but you have snowflake-connector-python 3.6.0 which is incompatible.\npython-kernel-startup 0.1.0 requires vegafusion==1.4.2, but you have vegafusion 1.5.0 which is incompatible.\npython-kernel-startup 0.1.0 requires vegafusion-python-embed==1.4.2, but you have vegafusion-python-embed 1.5.0 which is incompatible.\ntableauserverclient 0.24 requires packaging~=21.3, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.0.349 langchain-community-0.0.1 langchain-core-0.0.13 langchain-experimental-0.0.46 packaging-23.2\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting sqlalchemy-bigquery\n  Downloading sqlalchemy_bigquery-1.9.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy-bigquery) (2.11.0)\nRequirement already satisfied: google-auth<3.0.0dev,>=1.25.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy-bigquery) (2.17.1)\nRequirement already satisfied: google-cloud-bigquery<4.0.0dev,>=2.25.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy-bigquery) (3.13.0)\nRequirement already satisfied: packaging in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy-bigquery) (23.2)\nRequirement already satisfied: sqlalchemy<2.0.0dev,>=1.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy-bigquery) (1.4.25)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (1.59.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (4.24.1)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (2.28.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.25.0->sqlalchemy-bigquery) (5.3.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.25.0->sqlalchemy-bigquery) (0.2.8)\nRequirement already satisfied: six>=1.9.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.25.0->sqlalchemy-bigquery) (1.15.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.25.0->sqlalchemy-bigquery) (4.7.2)\nRequirement already satisfied: grpcio<2.0dev,>=1.47.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (1.50.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (1.22.1)\nRequirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (2.1.0)\nRequirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (2.0.3)\nRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (2.8.2)\nRequirement already satisfied: greenlet!=0.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from sqlalchemy<2.0.0dev,>=1.2.0->sqlalchemy-bigquery) (1.1.2)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (1.41.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=2.25.2->sqlalchemy-bigquery) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.25.0->sqlalchemy-bigquery) (0.4.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (2.0.6)\nRequirement already satisfied: idna<4,>=2.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (3.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->sqlalchemy-bigquery) (2021.10.8)\nDownloading sqlalchemy_bigquery-1.9.0-py2.py3-none-any.whl (33 kB)\nInstalling collected packages: sqlalchemy-bigquery\nSuccessfully installed sqlalchemy-bigquery-1.9.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"\"\"\"\nSetup the BigQuery engine for data previews and AI agent use\n\"\"\"\n\nfrom google.cloud import bigquery\nfrom google.oauth2 import service_account\nimport json\nfrom sqlalchemy import create_engine  # Table, MetaData, Integer, String, Column, ForeignKey, Float, Date\n\n# Path to your service account key file\nservice_account_file = 'bq_config.json'\n\n# Open and load the JSON file to get the credentials\nwith open(service_account_file, 'r') as file:\n    bq_creds_dict = json.load(file)\n\n# Load credentials from the dictionary\ncredentials = service_account.Credentials.from_service_account_info(bq_creds_dict)\n\n# Create a BigQuery client with the credentials\nclient = bigquery.Client(credentials=credentials)\n\n\ndatasets = list(client.list_datasets(project='bigquery-public-data'))\nif datasets:\n    print (\"Found datasets\")\nelse:\n    print(\"No datasets found.\")\n\n# Create SQLAlchemy engine\nengine = create_engine(\"bigquery://\", credentials_info=bq_creds_dict)","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Found datasets\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"select_dataset = _hex_json.loads(\"\\\"StackOverflow\\\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nConvert dataset names from friendly name to actual name\n\"\"\"\n\nif select_dataset == 'Austin Bikeshare':\n    prompt_dataset_name = 'bigquery-public-data.austin_bikeshare'\nelif select_dataset == 'US Census':\n    prompt_dataset_name = 'bigquery-public-data.census_bureau_usa'\nelif select_dataset == 'FHIR':\n    prompt_dataset_name = 'bigquery-public-data.fhir_synthea'\nelif select_dataset == 'Google Analytics 4':\n    prompt_dataset_name = 'bigquery-public-data.ga4_obfuscated_sample_ecommerce'\nelif select_dataset == 'FAA':\n    prompt_dataset_name = 'bigquery-public-data.faa'\nelif select_dataset == 'Google Cloud Release Notes':\n    prompt_dataset_name = 'bigquery-public-data.google_cloud_release_notes'\nelif select_dataset == 'Iowa Liquor Sales Forecast':\n    prompt_dataset_name = 'bigquery-public-data.iowa_liquor_sales_forecasting'\nelif select_dataset == 'Medicare':\n    prompt_dataset_name = 'bigquery-public-data.medicare'\nelif select_dataset == 'NCAA Basketball':\n    prompt_dataset_name = 'bigquery-public-data.ncaa_basketball'\nelif select_dataset == 'San Francisco Film Locations':\n    prompt_dataset_name = 'bigquery-public-data.san_francisco_film_locations'\nelif select_dataset == 'StackOverflow':\n    prompt_dataset_name = 'bigquery-public-data.stackoverflow'\nelif select_dataset == 'USA Popular Names':\n    prompt_dataset_name = 'bigquery-public-data.usa_names'\nelif select_dataset == 'Wikipedia':\n    prompt_dataset_name = 'bigquery-public-data.wikipedia'\nelse:\n    prompt_dataset_name = ''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nGet the table names for the specified dataset\n\"\"\"\n\nif prompt_dataset_name.strip() == '':\n    print(\"Dataset name is empty. Please provide a valid dataset name.\")\nelse:\n    try:\n        # List all tables in the dataset\n        dataset_tables = client.list_tables(prompt_dataset_name)\n\n        dataset_table_names = []\n        if dataset_tables:\n            print(f\"Found tables in dataset {prompt_dataset_name}:\")\n            for table in dataset_tables:\n                dataset_table_names.append(table.table_id)\n                print(f\"Table found: {table.table_id}\")\n        else:\n            print(f\"No tables found in dataset {prompt_dataset_name}.\")\n\n        print(\"All table names:\", dataset_table_names)\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Found tables in dataset bigquery-public-data.stackoverflow:\nTable found: badges\nTable found: comments\nTable found: post_history\nTable found: post_links\nTable found: posts_answers\nTable found: posts_moderator_nomination\nTable found: posts_orphaned_tag_wiki\nTable found: posts_privilege_wiki\nTable found: posts_questions\nTable found: posts_tag_wiki\nTable found: posts_tag_wiki_excerpt\nTable found: posts_wiki_placeholder\nTable found: stackoverflow_posts\nTable found: tags\nTable found: users\nTable found: votes\nAll table names: ['badges', 'comments', 'post_history', 'post_links', 'posts_answers', 'posts_moderator_nomination', 'posts_orphaned_tag_wiki', 'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', 'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', 'tags', 'users', 'votes']\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import json as _hex_json\nprompt_table = _hex_pks.kernel_execution.input_cell.run_dropdown_dynamic(args=_hex_types.DropdownDynamicArgs.from_dict({**_hex_json.loads(\"{\\\"dataframe_column\\\":null,\\\"ui_selected_value\\\":\\\"posts_answers\\\"}\"), **{_hex_json.loads(\"\\\"options_variable\\\"\"):_hex_kernel.variable_or_none(\"dataset_table_names\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()), interrupt_event=locals().get(\"_hex_interrupt_event\"))\n\nimport json as _hex_json\n_hex_pks.kernel_execution.input_cell.filled_dynamic_value(args=_hex_types.FilledDynamicValueArgs.from_dict({**_hex_json.loads(\"{\\\"variable_name\\\":\\\"dataset_table_names\\\",\\\"dataframe_column\\\":null,\\\"max_size\\\":10000,\\\"max_size_in_bytes\\\":5242880}\"), **{_hex_json.loads(\"\\\"variable\\\"\"):_hex_kernel.variable_or_none(\"dataset_table_names\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()), interrupt_event=locals().get(\"_hex_interrupt_event\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows_to_preview = _hex_json.loads(\"15\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nGenerated a preview of the selected table and sample size\n\"\"\"\n\ntable_to_query = prompt_dataset_name + \".\" + prompt_table\nrows_to_preview = rows_to_preview\n\n\npreview_query = f\"\"\"\nSELECT * \nFROM `{table_to_query}`\nLIMIT {rows_to_preview}\n\"\"\"\n\nquery_job = client.query(preview_query)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nUse Langchain to generate and store a table description. First look up if a description exists, if so display it. If one does not exist then generate a description.\n\"\"\"\n\nimport csv\nimport os\nfrom langchain.utilities import SQLDatabase\nfrom langchain.llms import OpenAI\nfrom langchain_experimental.sql import SQLDatabaseChain\n\ncsv_filename = \"table_descriptions.csv\"\ndescribe_prompt = f' describe {table_to_query}. Give a general description of the table and what it is for. Highlight the columns that are in the table, what each column contains.'\n\ndb = SQLDatabase(engine) #, include_tables=prompt_tables\nllm = OpenAI(temperature=0, verbose=True)\n\ndb_chain = SQLDatabaseChain.from_llm(llm, verbose=False,db=db, use_query_checker=True, top_k=10)\n\n# Check if the CSV file exists and read it into a dictionary\nif os.path.exists(csv_filename):\n    with open(csv_filename, mode=\"r\", newline=\"\") as csvfile:\n        reader = csv.DictReader(csvfile)\n        description_dict = {row[\"key\"]: row[\"description\"] for row in reader}\nelse:\n    description_dict = {}\n\n# Check if the description for table_to_query exists\nif table_to_query in description_dict:\n    print(description_dict[table_to_query])\nelse:\n    # Run the db_chain and store the output\n    description_output = db_chain.run(describe_prompt)\n    print(description_output)\n\n    # Add the new record to the CSV file\n    with open(csv_filename, mode=\"a\", newline=\"\") as csvfile:\n        fieldnames = [\"key\", \"description\"]\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        if not description_dict:  # If the dictionary is empty, write the header\n            writer.writeheader()\n        writer.writerow({\"key\": table_to_query, \"description\": description_output})","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"The table posts_answers contains the answers to questions posted on Stack Overflow. The columns in the table are id, title, body, accepted_answer_id, answer_count, comment_count, community_owned_date, creation_date, favorite_count, last_activity_date, last_edit_date, last_editor_display_name, last_editor_user_id, owner_display_name, owner_user_id, parent_id, post_type_id, score, tags, view_count.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"\"\"\"\nConvert the table to a dataframe for working with Pandas\n\"\"\"\n\nimport pandas as pd\n\ndataframe_table = query_job.to_dataframe()\ndataframe_table.head(rows_to_preview)","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"455658aa-ee04-480f-945a-3fd455933fa2/9f3e2ca6-e2d9-4be5-b2b1-d761a410618b/exports/459c6f8a-328e-45b6-a952-d2dd91b967f6"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>body</th>\n      <th>accepted_answer_id</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>favorite_count</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>parent_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>view_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>666919</td>\n      <td>None</td>\n      <td>&lt;p&gt;I think that DBDesigner don't draw links pr...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-20 16:28:36.123000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 16:28:36.123000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>noman</td>\n      <td>&lt;NA&gt;</td>\n      <td>637935</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>666956</td>\n      <td>None</td>\n      <td>&lt;p&gt;There are some real issues with argument al...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>2009-03-20 16:39:48.810000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 16:39:48.810000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Robert</td>\n      <td>&lt;NA&gt;</td>\n      <td>242894</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>666966</td>\n      <td>None</td>\n      <td>&lt;p&gt;Windows Server 2008 supports VPN capabiliti...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-20 16:42:52.970000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 16:42:52.970000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>jtdrummerboy</td>\n      <td>&lt;NA&gt;</td>\n      <td>19721</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>667041</td>\n      <td>None</td>\n      <td>&lt;p&gt;Looks like Silverlight 3 supports direct PC...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-20 16:59:03.210000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 16:59:03.210000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>585868</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>667297</td>\n      <td>None</td>\n      <td>&lt;p&gt;Login to the server that runs the IIS using...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-20 18:05:43.113000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 18:05:43.113000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Nate Vasquez</td>\n      <td>&lt;NA&gt;</td>\n      <td>168946</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>667670</td>\n      <td>None</td>\n      <td>&lt;p&gt;If you get two copies of splitter.py runnin...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n      <td>NaT</td>\n      <td>2009-03-20 19:40:18.253000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 19:40:18.253000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Andy V</td>\n      <td>&lt;NA&gt;</td>\n      <td>667500</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>668127</td>\n      <td>None</td>\n      <td>&lt;p&gt;The easy way to do it is to have the user t...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>2009-03-20 21:44:14.710000+00:00</td>\n      <td>None</td>\n      <td>2009-03-20 21:44:14.710000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Lucius Kwok</td>\n      <td>&lt;NA&gt;</td>\n      <td>79445</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>668487</td>\n      <td>None</td>\n      <td>&lt;p&gt;You can create some form of persistence usi...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 00:40:35.927000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 00:40:35.927000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Daniel Luyo</td>\n      <td>&lt;NA&gt;</td>\n      <td>667891</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>668609</td>\n      <td>None</td>\n      <td>&lt;p&gt;-- What about EXCEPT? (if this is SQL Serve...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 02:15:55.930000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 02:15:55.930000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>666595</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>668671</td>\n      <td>None</td>\n      <td>&lt;p&gt;alternatively you could use lastfm web serv...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 03:16:12.587000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 03:16:12.587000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>maxim</td>\n      <td>&lt;NA&gt;</td>\n      <td>664771</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>668731</td>\n      <td>None</td>\n      <td>&lt;p&gt;Don't use Singletons where state may change...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 04:16:49.447000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 04:16:49.447000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Sin</td>\n      <td>&lt;NA&gt;</td>\n      <td>660463</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>668782</td>\n      <td>None</td>\n      <td>&lt;p&gt;The [^] regex modifier only works on single...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 05:17:01.017000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 05:17:01.017000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>AtnNn</td>\n      <td>&lt;NA&gt;</td>\n      <td>668750</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>669057</td>\n      <td>None</td>\n      <td>&lt;p&gt;I got a similar problem.. Here's the soluti...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 09:53:17.173000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 09:53:17.173000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Kalpesh</td>\n      <td>&lt;NA&gt;</td>\n      <td>548709</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>669128</td>\n      <td>None</td>\n      <td>&lt;p&gt;You need to post some actual code. The valu...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 11:06:38.680000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 11:06:38.680000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>anon</td>\n      <td>&lt;NA&gt;</td>\n      <td>669105</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>669132</td>\n      <td>None</td>\n      <td>&lt;p&gt;You can have one class which has listener m...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>2009-03-21 11:09:59.330000+00:00</td>\n      <td>None</td>\n      <td>2009-03-21 11:09:59.330000+00:00</td>\n      <td>NaT</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>Ivan Babanin</td>\n      <td>&lt;NA&gt;</td>\n      <td>669099</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"\"\"\"\nDisplay stats for all columns in the table\n\"\"\"\n\ndataframe_table.describe(include='all', datetime_is_numeric=True)\n\n# Note: This is currently only showing the stats for the preview set of data, needs to be expanded to show all data but it was crashing the notebook due to lack of memory","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"455658aa-ee04-480f-945a-3fd455933fa2/9f3e2ca6-e2d9-4be5-b2b1-d761a410618b/exports/5b32252c-925f-48cf-8be4-2ee4b5c4e9af"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>body</th>\n      <th>accepted_answer_id</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>favorite_count</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>parent_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>view_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>&lt;NA&gt;</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>&lt;NA&gt;</td>\n      <td>13</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;p&gt;I think that DBDesigner don't draw links pr...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>noman</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>668104.866667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.266667</td>\n      <td>NaT</td>\n      <td>2009-03-21 00:25:08.485333248+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-21 00:25:08.485333248+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>507846.133333</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>666919.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaT</td>\n      <td>2009-03-20 16:28:36.123000+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-20 16:28:36.123000+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>19721.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>667169.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaT</td>\n      <td>2009-03-20 17:32:23.161499904+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-20 17:32:23.161499904+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>395801.5</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>668487.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaT</td>\n      <td>2009-03-21 00:40:35.927000064+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-21 00:40:35.927000064+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>660463.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668756.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaT</td>\n      <td>2009-03-21 04:46:55.232000+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-21 04:46:55.232000+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>667695.5</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>669132.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaT</td>\n      <td>2009-03-21 11:09:59.330000+00:00</td>\n      <td>NaN</td>\n      <td>2009-03-21 11:09:59.330000+00:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>669105.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>869.188856</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.593617</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>244020.800235</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"dataframe_table","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_prompt = _hex_json.loads(\"\\\"Which post had the most answers and what was the question, and what was the most popular answer and which user answered it \\\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_prompt = _hex_json.loads(\"false\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nUse Langchain to query the database for the user. Converts their natural language prompt to SQL.\n\"\"\"\n\n# TODO: Switch to agentic model that can handle errors\n\nsystem_prompt = f' in {table_to_query}.You are a BigQuery expert. You are able quickly review the tables in a dataset and understand the contents of each table along with their relation. You will be asked a question for which you need to generate and execute a query. The table in the question is the main focus of the question, but you may also need to join to other tables, so keep them in mind as your create your plan. The other tables are {dataset_table_names}. The column names may not match 1:1 in the prompt, use your best reasoning to select a column (for instance a user may ask for an account but in the table the column is account_name).Ensure that the columns you use in the query exist in the table. As you answer the users question, consider what other columns may be additive to their question and include those in your response'\nfull_prompt = user_prompt + system_prompt\n\n\nif run_prompt:\n   \n    \n    from langchain.utilities import SQLDatabase\n    from langchain.llms import OpenAI\n    from langchain_experimental.sql import SQLDatabaseChain\n    \n    db = SQLDatabase(engine) # include_tables=dataset_tables_to_query\n    llm = OpenAI(temperature=0, verbose=True)\n\n    db_chain = SQLDatabaseChain.from_llm(llm, verbose=True,db=db, use_query_checker=True, top_k=10)\n\n    db_chain.run(full_prompt)\n\nelse: \n    display(\"Waiting on you to run the query\")","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"\n\n\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\nWhich post had the most answers and what was the question, and what was the most popular answer and which user answered it  in bigquery-public-data.stackoverflow.posts_answers.You are a BigQuery expert. You are able quickly review the tables in a dataset and understand the contents of each table along with their relation. You will be asked a question for which you need to generate and execute a query. The table in the question is the main focus of the question, but you may also need to join to other tables, so keep them in mind as your create your plan. The other tables are ['badges', 'comments', 'post_history', 'post_links', 'posts_answers', 'posts_moderator_nomination', 'posts_orphaned_tag_wiki', 'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', 'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', 'tags', 'users', 'votes']. The column names may not match 1:1 in the prompt, use your best reasoning to select a column (for instance a user may ask for an account but in the table the column is account_name).Ensure that the columns you use in the query exist in the table. As you answer the users question, consider what other columns may be additive to their question and include those in your response\nSQLQuery:\u001b[32;1m\u001b[1;3mSELECT pq.title, pa.body, pa.score, u.display_name\nFROM `bigquery-public-data.stackoverflow.posts_questions` AS pq\nJOIN `bigquery-public-data.stackoverflow.posts_answers` AS pa\nON pq.id = pa.parent_id\nJOIN `bigquery-public-data.stackoverflow.users` AS u\nON pa.owner_user_id = u.id\nORDER BY pa.score DESC\nLIMIT 10\u001b[0m\nSQLResult: \u001b[33;1m\u001b[1;3m[('Why is processing a sorted array faster than processing an unsorted array?', '<p><strong>You are a victim of <a href=\"https://en.wikipedia.org/wiki/Branch_predictor\" rel=\"noreferrer\">branch prediction</a> fail.</strong></p>\\n<hr />\\n<h2>What is Branch Prediction?</h2>\\n<p>Consider a railroad junction:</p>\\n<p><a...', 34269, 'Mysticial'), ('How do I undo the most recent local commits in Git?', '<h1>Undo a commit &amp; redo</h1>\\n<pre class=\"lang-sh prettyprint-override\"><code>$ git commit -m &quot;Something terribly misguided&quot; # (0: Your Accident)\\n$ git reset HEAD~                              # (1)\\n[ edit files as necessary ]                    # (2)\\n$ git add .                   ...', 27023, 'Esko Luontola'), ('How do I delete a Git branch locally and remotely?', '<h1>Executive Summary</h1>\\n<pre><code>git push -d &lt;remote_name&gt; &lt;branchname&gt;\\ngit branch -d &lt;branchname&gt;\\n</code></pre>\\n<p><strong>Note:</strong> In most cases, <code>&lt;remote_name&gt;</code> will be <code>origin</code>.</p>\\n<h1>Delete Local Branch</h1>\\n<p>To delete the...', 24567, 'Matthew Rankin'), ('How to modify existing, unpushed commit messages?', '<h1>Amending the most recent commit message</h1>\\n<pre class=\"lang-sh prettyprint-override\"><code>git commit --amend\\n</code></pre>\\n<p>will open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command...', 17827, 'EfForEffort'), ('How do I rename a local Git branch?', '<p>To rename the current branch:</p>\\n<pre><code>git branch -m &lt;newname&gt;\\n</code></pre>\\n<p>To rename a branch while pointed to any branch:</p>\\n<pre><code>git branch -m &lt;oldname&gt; &lt;newname&gt;\\n</code></pre>\\n<p><code>-m</code> is short for <code>--move</code>.</p>\\n<hr />\\n<p>To push the...', 17541, 'siride'), ('What does the \"yield\" keyword do?', '<p>To understand what <code>yield</code> does, you must understand what <em>generators</em> are. And before you can understand generators, you must understand <em>iterables</em>.</p>\\n<h2>Iterables</h2>\\n<p>When you create a list, you can read its items one by one. Reading its items one by one is...', 17250, 'e-satis'), ('How do I redirect to another webpage?', '<h2>One does not simply redirect using jQuery</h2>\\n\\n<p>jQuery is not necessary, and <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Location/replace\" rel=\"noreferrer\"><strong><code>window.location.replace(...)</code></strong></a> will best simulate an HTTP redirect. ...', 16001, 'Ryan McGeary'), ('How can I remove a specific item from an array?', '<p>Find the <code>index</code> of the array element you want to remove using <a href=\"https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array/indexOf\" rel=\"noreferrer\"><code>indexOf</code></a>, and then remove that index with <a...', 15553, 'Tom Wadley'), ('How to check whether a string contains a substring in JavaScript?', '<p>ECMAScript\\xa06  introduced <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\" rel=\"noreferrer\"><code>String.prototype.includes</code></a>:</p>\\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\"...', 15389, 'Fabien M√©nager'), (\"How do I undo 'git add' before commit?\", '<p>Undo <code>git add</code> for uncommitted changes with:</p>\\n<pre><code>git reset &lt;file&gt;\\n</code></pre>\\n<p>That will remove the file from the current index (the &quot;about to be committed&quot; list) without changing anything else.</p>\\n<hr />\\n<p>To unstage all changes for all...', 12688, 'genehack')]\u001b[0m\nAnswer:\u001b[32;1m\u001b[1;3mThe post with the most answers was \"Why is processing a sorted array faster than processing an unsorted array?\", with 34269 answers. The most popular answer was given by user Mysticial, and it was \"You are a victim of branch prediction fail.\"\u001b[0m\n\u001b[1m> Finished chain.\u001b[0m\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"\"\"\"\nUse Langchain to generate an explanation of relationships between tables\n\"\"\"\n\n# TODO: Store these like we do the descriptions\n# TODO: Add error handling\n# TODO: Replace with AI generated ERD\n\nrelationship_prompt = f' Describe the relationship between {table_to_query} and the other tables in the dataset.'\n\ndb = SQLDatabase(engine) #, include_tables=prompt_tables\nllm = OpenAI(temperature=0, verbose=True)\n\ndb_chain = SQLDatabaseChain.from_llm(llm, verbose=False,db=db, use_query_checker=True, top_k=1)\n\nrelationship_output = db_chain.run(relationship_prompt)\nprint(relationship_output)","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"The relationship between bigquery-public-data.stackoverflow.posts_answers and the other tables in the dataset is that the posts_answers table contains answers to questions in the posts_questions table, with each answer having a score and body associated with it.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":null,"project_id":"9f3e2ca6-e2d9-4be5-b2b1-d761a410618b","version":"draft","exported_date":"Mon Jan 01 2024 20:57:15 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}